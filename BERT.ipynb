{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9111a5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install bert-for-tf2 >> /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76216cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade grpcio >> /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae138f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tqdm  >> /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8f3768",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sentencepiece >> /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef505ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gdown"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186c26ec",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d534defb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import math\n",
    "import datetime\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "import bert\n",
    "from bert import BertModelLayer\n",
    "from bert.loader import StockBertConfig, map_stock_config_to_params, load_stock_weights\n",
    "from bert.tokenization.bert_tokenization import FullTokenizer\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pylab import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from matplotlib import rc\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "\n",
    "sns.set(style='whitegrid', palette='muted', font_scale=1.2)\n",
    "\n",
    "HAPPY_COLORS_PALETTE = [\"#01BEFE\", \"#FFDD00\", \"#FF7D00\", \"#FF006D\", \"#ADFF02\", \"#8F00FF\"]\n",
    "\n",
    "sns.set_palette(sns.color_palette(HAPPY_COLORS_PALETTE))\n",
    "\n",
    "rcParams['figure.figsize'] = 12, 8\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "np.random.seed(RANDOM_SEED)\n",
    "tf.random.set_seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7696081b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"cleaned-data.csv\")\n",
    "\n",
    "train=df.sample(frac=0.5).reset_index(drop=True)\n",
    "test=df.sample(frac=0.1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f76ba8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f059b2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train.Genres.unique().tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d537e5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexNames = []\n",
    "for index, row in train.iterrows():\n",
    "    if len(row.Genres.split(\"; \"))>1:\n",
    "        indexNames.append(index)\n",
    "train = train.drop(indexNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31006d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc46c19",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b92f00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "chart = sns.countplot(train.Genres, palette=HAPPY_COLORS_PALETTE)\n",
    "plt.title(\"Number of songs per genre\")\n",
    "chart.set_xticklabels(chart.get_xticklabels(), rotation=30, horizontalalignment='right');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc2e3d3",
   "metadata": {},
   "source": [
    "# Remover genres com menos de 2000 exemplos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ceba93",
   "metadata": {},
   "outputs": [],
   "source": [
    "for genre in train.Genres.unique().tolist():\n",
    "    if len(train[train.Genres==genre])<2000:\n",
    "        train.drop(train[train.Genres==genre].index.tolist(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0736ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train.Genres.unique().tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9744c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "chart = sns.countplot(train.Genres, palette=HAPPY_COLORS_PALETTE)\n",
    "plt.title(\"Number of songs per genre\")\n",
    "chart.set_xticklabels(chart.get_xticklabels(), rotation=30, horizontalalignment='right');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e676710",
   "metadata": {},
   "source": [
    "# Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6279019c",
   "metadata": {},
   "outputs": [],
   "source": [
    "genres_size=None\n",
    "\n",
    "for genre in train.Genres.unique().tolist():\n",
    "    if genres_size is not None:\n",
    "        genres_size=min(genres_size, train[train.Genres==genre].shape[0])\n",
    "    else:\n",
    "        genres_size=train[train.Genres==genre].shape[0]\n",
    "    \n",
    "print(genres_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e75c03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train.shape)\n",
    "for genre in train.Genres.unique().tolist():\n",
    "    indexes=train[train.Genres==genre].index.tolist()\n",
    "    #Apenas para poupar recursos computacionais e porque já conheço o dataset vou pôr 3000 hardcoded, na linha debaixo está o código original para fazer undersampling para a dimensão da calsse menos populada\n",
    "    #num_to_drop=len(indexes)-genres_size\n",
    "    #indexes_to_drop=indexes[:-genres_size]\n",
    "    indexes_to_drop=indexes[:-2000]\n",
    "    train.drop(indexes_to_drop, inplace=True)\n",
    "print(train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a89dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexNames = []\n",
    "for index, row in test.iterrows():\n",
    "    if row.Genres not in train.Genres.unique().tolist():\n",
    "        indexNames.append(index)\n",
    "test = test.drop(indexNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56815720",
   "metadata": {},
   "outputs": [],
   "source": [
    "chart = sns.countplot(train.Genres, palette=HAPPY_COLORS_PALETTE)\n",
    "plt.title(\"Number of songs per genre\")\n",
    "chart.set_xticklabels(chart.get_xticklabels(), rotation=30, horizontalalignment='right');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f2c2549",
   "metadata": {},
   "source": [
    "# Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef709bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE=16384\n",
    "INPUT_LENGTH=265\n",
    "\n",
    "x = np.array(train['Lyric'])\n",
    "y = np.array(train['Genres'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2651255",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer to transform lyrics into tokens\n",
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
    "    num_words=VOCAB_SIZE,\n",
    "    filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n",
    "    lower=True, split=' ', char_level=False, oov_token=None,\n",
    "    #document_count=0, **kwargs\n",
    ")\n",
    "\n",
    "# updates internal vocabulary based on the lyrics\n",
    "tokenizer.fit_on_texts(x)\n",
    "\n",
    "# transform each text in x to a sequence of tokens\n",
    "x = tokenizer.texts_to_sequences(x)\n",
    "\n",
    "# pads/cuts sequences to the same length\n",
    "x = pad_sequences(x, maxlen = INPUT_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec2ec0af",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c11f225",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://storage.googleapis.com/bert_models/2018_10_18/uncased_L-12_H-768_A-12.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7dba7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip uncased_L-12_H-768_A-12.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3e3704",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "os.makedirs(\"model\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6afad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_model_name=\"uncased_L-12_H-768_A-12\"\n",
    "\n",
    "bert_ckpt_dir = os.path.join(\"model/\", bert_model_name)\n",
    "bert_ckpt_file = os.path.join(bert_ckpt_dir, \"bert_model.ckpt\")\n",
    "bert_config_file = os.path.join(bert_ckpt_dir, \"bert_config.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e389a8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenreDetectionData:\n",
    "  DATA_COLUMN = \"Lyric\"\n",
    "  LABEL_COLUMN = \"Genres\"\n",
    "\n",
    "  def __init__(self, train, test, tokenizer: FullTokenizer, classes, max_seq_len=192):\n",
    "    self.tokenizer = tokenizer\n",
    "    self.max_seq_len = 0\n",
    "    self.classes = classes\n",
    "    \n",
    "    ((self.train_x, self.train_y), (self.test_x, self.test_y)) = map(self._prepare, [train, test])\n",
    "\n",
    "    print(\"max seq_len\", self.max_seq_len)\n",
    "    self.max_seq_len = min(self.max_seq_len, max_seq_len)\n",
    "    self.train_x, self.test_x = map(self._pad, [self.train_x, self.test_x])\n",
    "\n",
    "  def _prepare(self, df):\n",
    "    x, y = [], []\n",
    "    \n",
    "    for _, row in tqdm(df.iterrows()):\n",
    "      text, label = row[GenreDetectionData.DATA_COLUMN], row[GenreDetectionData.LABEL_COLUMN]\n",
    "      tokens = self.tokenizer.tokenize(text)\n",
    "      tokens = [\"[CLS]\"] + tokens + [\"[SEP]\"]\n",
    "      token_ids = self.tokenizer.convert_tokens_to_ids(tokens)\n",
    "      self.max_seq_len = max(self.max_seq_len, len(token_ids))\n",
    "      x.append(token_ids)\n",
    "      y.append(self.classes.index(label))\n",
    "\n",
    "    return np.array(x), np.array(y)\n",
    "\n",
    "  def _pad(self, ids):\n",
    "    x = []\n",
    "    for input_ids in ids:\n",
    "      input_ids = input_ids[:min(len(input_ids), self.max_seq_len - 2)]\n",
    "      input_ids = input_ids + [0] * (self.max_seq_len - len(input_ids))\n",
    "      x.append(np.array(input_ids))\n",
    "    return np.array(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f222f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(max_seq_len, bert_ckpt_file):\n",
    "\n",
    "  with tf.io.gfile.GFile(bert_config_file, \"r\") as reader:\n",
    "      bc = StockBertConfig.from_json_string(reader.read())\n",
    "      bert_params = map_stock_config_to_params(bc)\n",
    "      bert_params.adapter_size = None\n",
    "      bert = BertModelLayer.from_params(bert_params, name=\"bert\")\n",
    "        \n",
    "  input_ids = keras.layers.Input(shape=(max_seq_len, ), dtype='int32', name=\"input_ids\")\n",
    "  bert_output = bert(input_ids)\n",
    "\n",
    "  print(\"bert shape\", bert_output.shape)\n",
    "\n",
    "  cls_out = keras.layers.Lambda(lambda seq: seq[:, 0, :])(bert_output)\n",
    "  cls_out = keras.layers.Dropout(0.5)(cls_out)\n",
    "  logits = keras.layers.Dense(units=768, activation=\"tanh\")(cls_out)\n",
    "  logits = keras.layers.Dropout(0.5)(logits)\n",
    "  logits = keras.layers.Dense(units=len(classes), activation=\"softmax\")(logits)\n",
    "\n",
    "  model = keras.Model(inputs=input_ids, outputs=logits)\n",
    "  model.build(input_shape=(None, max_seq_len))\n",
    "\n",
    "  load_stock_weights(bert, bert_ckpt_file)\n",
    "        \n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ca9c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = FullTokenizer(vocab_file=os.path.join(bert_ckpt_dir, \"vocab.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07df28dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "classes = train.Genres.unique().tolist()\n",
    "data = GenreDetectionData(train, test, tokenizer, classes, max_seq_len=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb55e62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model(data.max_seq_len, bert_ckpt_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ffe737",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb79566",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "  optimizer=keras.optimizers.Adam(1e-5),\n",
    "  loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "  metrics=[keras.metrics.SparseCategoricalAccuracy(name=\"acc\")]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb337cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = \"log/intent_detection/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%s\")\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=log_dir)\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1,patience=2)\n",
    "\n",
    "history = model.fit(\n",
    "  x=data.train_x, \n",
    "  y=data.train_y,\n",
    "  validation_split=0.1,\n",
    "  batch_size=32,\n",
    "  shuffle=True,\n",
    "  epochs=10,\n",
    "  callbacks=[tensorboard_callback, es]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52173554",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bfee3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5b7798",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.figure().gca()\n",
    "ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "\n",
    "ax.plot(history.history['loss'])\n",
    "ax.plot(history.history['val_loss'])\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['train', 'test'])\n",
    "plt.title('Loss over training epochs')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2981d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.figure().gca()\n",
    "ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "\n",
    "ax.plot(history.history['acc'])\n",
    "ax.plot(history.history['val_acc'])\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['train', 'test'])\n",
    "plt.title('Accuracy over training epochs')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a8ded8",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, train_acc = model.evaluate(data.train_x, data.train_y)\n",
    "_, test_acc = model.evaluate(data.test_x, data.test_y)\n",
    "\n",
    "print(\"train acc\", train_acc)\n",
    "print(\"test acc\", test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c191da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(data.test_x).argmax(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fccb541",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(data.test_y, y_pred, target_names=classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab653d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(data.test_y, y_pred)\n",
    "df_cm = pd.DataFrame(cm, index=classes, columns=classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8506216",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hmap = sns.heatmap(df_cm, annot=True, fmt=\"d\")\n",
    "hmap.yaxis.set_ticklabels(hmap.yaxis.get_ticklabels(), rotation=0, ha='right')\n",
    "hmap.xaxis.set_ticklabels(hmap.xaxis.get_ticklabels(), rotation=30, ha='right')\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9c1c63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27606912",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a88eb40",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
