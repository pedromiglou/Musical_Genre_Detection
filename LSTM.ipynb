{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f04e1d8",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405f8650",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Conv1D\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.layers import GlobalMaxPooling1D\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd6a4942",
   "metadata": {},
   "source": [
    "## Read/Transform Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9da6ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read data\n",
    "df = pd.read_csv('cleaned-data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8962f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#join and shuffle data\n",
    "df = df.sample(frac=1).reset_index(drop=True) #sample shuffles the data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86853ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexNames = []\n",
    "for index, row in df.iterrows():\n",
    "    if len(row.Genres.split(\"; \"))>1 or (row.Genres != \"Pop\" and row.Genres!=\"Rap\"):\n",
    "        indexNames.append(index)\n",
    "df = df.drop(indexNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3c1ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(df['Lyric']) #\"text\"\n",
    "y = np.array(df['Genres'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73dbe490",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(df['Genres']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16adf88",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Genres'].value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4696d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer to transform text into tokens\n",
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
    "    num_words=200000,\n",
    "    filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n",
    "    lower=True, split=' ', char_level=False, oov_token=None,\n",
    "    #document_count=0, **kwargs\n",
    ")\n",
    "\n",
    "# Updates internal vocabulary based on a list of texts.\n",
    "tokenizer.fit_on_texts(x)\n",
    "\n",
    "#Transforms each text in x to a sequence of integers.\n",
    "x = tokenizer.texts_to_sequences(x)\n",
    "\n",
    "#Pads sequences to the same length. In this case, with maxlen of 100 integers\n",
    "x = pad_sequences(x, maxlen = 250)\n",
    "\n",
    "# tokenizer to transform text into tokens\n",
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
    "    num_words=100000,\n",
    "    filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n",
    "    lower=True, split=' ', char_level=False, oov_token=None,\n",
    "    #document_count=0, **kwargs\n",
    ")\n",
    "\n",
    "# Updates internal vocabulary based on a list of texts.\n",
    "tokenizer.fit_on_texts(y)\n",
    "\n",
    "#Transforms each text in x to a sequence of integers.\n",
    "y = tokenizer.texts_to_sequences(y)\n",
    "\n",
    "y = np.array([temp[0]-1 for temp in y])\n",
    "\n",
    "#Pads sequences to the same length. In this case, with maxlen of 100 integers\n",
    "#y = pad_sequences(x, maxlen = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7cf660",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM_Model(vocab_size=200000, features=500, input_length=250, learning_rate=0.00001, dropout=0):\n",
    "    model=Sequential()\n",
    "    # Embedding layer\n",
    "    model.add(Embedding(vocab_size,features,input_length=input_length))\n",
    "    # Long Short Term Memory layer\n",
    "    model.add(LSTM(200, dropout=dropout))\n",
    "    # Output layer\n",
    "    model.add(Dense(1,activation='sigmoid'))\n",
    "    model.compile(loss=keras.losses.binary_crossentropy, optimizer=keras.optimizers.Adam(learning_rate=learning_rate), metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3767c43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=0)\n",
    "model = LSTM_Model()\n",
    "res = model.fit(x_train,y_train,validation_data=(x_test,y_test),epochs=20,batch_size=64)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
